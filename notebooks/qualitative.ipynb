{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "373e33a4",
   "metadata": {},
   "source": [
    "# Some steering examples\n",
    "This notebook showcases and reproduces some of the steering examples from our LessWrong post\n",
    "\n",
    "<span style=\"color:red\">When running this in Google Colab, be sure to set your runtime Hardware Accelerator to GPU and your Runtime Shape to High-RAM.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f14380e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9026d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error importing huggingface_hub.hf_api: stat: path should be string, bytes, os.PathLike or integer, not function\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "stat: path should be string, bytes, os.PathLike or integer, not function",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Dict, Union, Callable, Tuple\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfunctools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m partial, lru_cache\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LlamaForCausalLM, LlamaTokenizer\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mactivation_additions\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ActivationAddition, get_x_vector, print_n_comparisons, get_n_comparisons, pretty_print_completions\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01maccelerate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_empty_weights, load_checkpoint_and_dispatch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/transformers/__init__.py:27\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     29\u001b[39m     OptionalDependencyNotAvailable,\n\u001b[32m     30\u001b[39m     _LazyModule,\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     is_pretty_midi_available,\n\u001b[32m     37\u001b[39m )\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Note: the following symbols are deliberately exported with `as`\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# so that mypy, pylint or other static linters can recognize them,\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# given that they are not exported using `__all__` in this file.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/transformers/dependency_versions_check.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdependency_versions_table\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[32m     25\u001b[39m pkgs_to_check_at_runtime = [\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtqdm\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpyyaml\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/transformers/utils/__init__.py:19\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#!/usr/bin/env python\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Copyright 2021 The HuggingFace Inc. team. All rights reserved.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfunctools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lru_cache\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_full_repo_name  \u001b[38;5;66;03m# for backward compatibility\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HF_HUB_DISABLE_TELEMETRY \u001b[38;5;28;01mas\u001b[39;00m DISABLE_TELEMETRY  \u001b[38;5;66;03m# for backward compatibility\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpackaging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1412\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/__init__.py:1044\u001b[39m, in \u001b[36m_attach.<locals>.__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m   1042\u001b[39m submod_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1043\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m     submod = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError importing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubmod_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/importlib/__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     86\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/hf_api.py:56\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontrib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconcurrent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_commit_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     57\u001b[39m     CommitOperation,\n\u001b[32m     58\u001b[39m     CommitOperationAdd,\n\u001b[32m     59\u001b[39m     CommitOperationCopy,\n\u001b[32m     60\u001b[39m     CommitOperationDelete,\n\u001b[32m     61\u001b[39m     _fetch_files_to_copy,\n\u001b[32m     62\u001b[39m     _fetch_upload_modes,\n\u001b[32m     63\u001b[39m     _prepare_commit_payload,\n\u001b[32m     64\u001b[39m     _upload_files,\n\u001b[32m     65\u001b[39m     _warn_on_overwriting_operations,\n\u001b[32m     66\u001b[39m )\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inference_endpoints\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InferenceEndpoint, InferenceEndpointType\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_jobs_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JobInfo, JobSpec, ScheduledJobInfo, _create_job_spec\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/_commit_api.py:20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EntryNotFoundError, HfHubHTTPError, XetAuthorizationError, XetRefreshTokenError\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile_download\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hf_hub_url\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlfs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UploadInfo, lfs_upload, post_lfs_batch_info\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     23\u001b[39m     FORBIDDEN_FOLDERS,\n\u001b[32m     24\u001b[39m     XetTokenType,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     validate_hf_hub_args,\n\u001b[32m     34\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/file_download.py:22\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     19\u001b[39m     __version__,  \u001b[38;5;66;03m# noqa: F401 # for backward compatibility\u001b[39;00m\n\u001b[32m     20\u001b[39m     constants,\n\u001b[32m     21\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_local_folder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_local_download_paths, read_download_metadata, write_download_metadata\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     24\u001b[39m     HUGGINGFACE_CO_URL_TEMPLATE,  \u001b[38;5;66;03m# noqa: F401 # for backward compatibility\u001b[39;00m\n\u001b[32m     25\u001b[39m     HUGGINGFACE_HUB_CACHE,  \u001b[38;5;66;03m# noqa: F401 # for backward compatibility\u001b[39;00m\n\u001b[32m     26\u001b[39m )\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     28\u001b[39m     EntryNotFoundError,\n\u001b[32m     29\u001b[39m     FileMetadataError,\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m     RevisionNotFoundError,\n\u001b[32m     35\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/_local_folder.py:61\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WeakFileLock\n\u001b[32m     64\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mLocalDownloadFilePaths\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/utils/__init__.py:37\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     BadRequestError,\n\u001b[32m     19\u001b[39m     CacheNotFound,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     SafetensorsParsingError,\n\u001b[32m     34\u001b[39m )\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m _tqdm  \u001b[38;5;66;03m# _tqdm is the module\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_auth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_stored_tokens, get_token\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_cache_assets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cached_assets_path\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_cache_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     40\u001b[39m     CachedFileInfo,\n\u001b[32m     41\u001b[39m     CachedRepoInfo,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     scan_cache_dir,\n\u001b[32m     46\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/utils/_auth.py:25\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Optional\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_runtime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_colab_enterprise, is_google_colab\n\u001b[32m     28\u001b[39m _IS_GOOGLE_COLAB_CHECKED = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     29\u001b[39m _GOOGLE_COLAB_SECRET_LOCK = Lock()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/huggingface_hub/utils/_runtime.py:68\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m package_names:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         _package_versions[candidate_name] = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m importlib.metadata.PackageNotFoundError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/importlib/metadata/__init__.py:987\u001b[39m, in \u001b[36mversion\u001b[39m\u001b[34m(distribution_name)\u001b[39m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mversion\u001b[39m(distribution_name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    981\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the version string for the named package.\u001b[39;00m\n\u001b[32m    982\u001b[39m \n\u001b[32m    983\u001b[39m \u001b[33;03m    :param distribution_name: The name of the distribution package to query.\u001b[39;00m\n\u001b[32m    984\u001b[39m \u001b[33;03m    :return: The version string for the package as defined in the package's\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[33;03m        \"Version\" metadata key.\u001b[39;00m\n\u001b[32m    986\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m987\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m.version\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/importlib/metadata/__init__.py:960\u001b[39m, in \u001b[36mdistribution\u001b[39m\u001b[34m(distribution_name)\u001b[39m\n\u001b[32m    954\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdistribution\u001b[39m(distribution_name: \u001b[38;5;28mstr\u001b[39m) -> Distribution:\n\u001b[32m    955\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the ``Distribution`` instance for the named package.\u001b[39;00m\n\u001b[32m    956\u001b[39m \n\u001b[32m    957\u001b[39m \u001b[33;03m    :param distribution_name: The name of the distribution package as a string.\u001b[39;00m\n\u001b[32m    958\u001b[39m \u001b[33;03m    :return: A ``Distribution`` instance (or subclass thereof).\u001b[39;00m\n\u001b[32m    959\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m960\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDistribution\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistribution_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/importlib/metadata/__init__.py:407\u001b[39m, in \u001b[36mDistribution.from_name\u001b[39m\u001b[34m(cls, name)\u001b[39m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mA distribution name is required.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdiscover\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    409\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PackageNotFoundError(name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/importlib/metadata/__init__.py:891\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    888\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Find metadata directories in paths heuristically.\"\"\"\u001b[39;00m\n\u001b[32m    889\u001b[39m prepared = Prepared(name)\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m itertools.chain.from_iterable(\n\u001b[32m--> \u001b[39m\u001b[32m891\u001b[39m     \u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepared\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(FastPath, paths)\n\u001b[32m    892\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/importlib/metadata/__init__.py:757\u001b[39m, in \u001b[36mFastPath.search\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lookup(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmtime\u001b[49m).search(name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/importlib/metadata/__init__.py:762\u001b[39m, in \u001b[36mFastPath.mtime\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    759\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    760\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmtime\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    761\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mOSError\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m762\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m.st_mtime\n\u001b[32m    763\u001b[39m     \u001b[38;5;28mself\u001b[39m.lookup.cache_clear()\n",
      "\u001b[31mTypeError\u001b[39m: stat: path should be string, bytes, os.PathLike or integer, not function"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import activation_additions as aa\n",
    "from typing import List, Dict, Union, Callable, Tuple\n",
    "from functools import partial, lru_cache\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from activation_additions.compat import ActivationAddition, get_x_vector, print_n_comparisons, get_n_comparisons, pretty_print_completions\n",
    "from accelerate import init_empty_weights, load_checkpoint_and_dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ef0533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f6146a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68dc0edc7504add9d4df97e74ce650b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path: str = \"../models/llama-13B\"\n",
    "device: str = \"mps\" if torch.has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "with init_empty_weights():\n",
    "    model = LlamaForCausalLM.from_pretrained(model_path)#, load_in_8bit=True, device_map={'': device})\n",
    "    model.tie_weights() # in case checkpoint doesn't contain duplicate keys for tied weights\n",
    "\n",
    "# {0: '20G', 1: '20G'}\n",
    "model = load_checkpoint_and_dispatch(model, model_path, device_map={'': device}, dtype=torch.float16, no_split_module_classes=[\"LlamaDecoderLayer\"])\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path)\n",
    "model.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0526bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_kwargs: Dict[str, Union[float, int]] = {\n",
    "    \"temperature\": 1.0,\n",
    "    \"top_p\": 0.3,\n",
    "    \"freq_penalty\": 1.0,\n",
    "    \"num_comparisons\": 3,\n",
    "    \"tokens_to_generate\": 50,\n",
    "    \"seed\": 0,  # For reproducibility\n",
    "}\n",
    "get_x_vector_preset: Callable = partial(\n",
    "    get_x_vector,\n",
    "    pad_method=\"tokens_right\",\n",
    "    model=model,\n",
    "    custom_pad_id=int(model.tokenizer.encode(\" \")[0]),\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d67b14f",
   "metadata": {},
   "source": [
    "### Example 1: Love - Hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90027c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+--------------------------------------------------------------+\n",
      "|                    \u001b[1mUnsteered completions\u001b[0m                     |                     \u001b[1mSteered completions\u001b[0m                      |\n",
      "+--------------------------------------------------------------+--------------------------------------------------------------+\n",
      "|              \u001b[1mI hate you because\u001b[0m you are a liar.              |             \u001b[1mI hate you because\u001b[0m you are my life.              |\n",
      "|   I hate you because you are not the person I thought you    |                You are the reason why I live.                |\n",
      "|                            were.                             |        I love you because you make me feel so happy.         |\n",
      "|  I hate you because I wasted my time on someone who didn’t   |        You are the one who makes me smile every day.         |\n",
      "|                         deserve it.                          |       I love you because I want to be with you forever       |\n",
      "|              I hate that we were once friends a              |                                                              |\n",
      "+--------------------------------------------------------------+--------------------------------------------------------------+\n",
      "|           \u001b[1mI hate you because\u001b[0m you're so beautiful.            |       \u001b[1mI hate you because\u001b[0m you have been so good to me.        |\n",
      "|             I hate you because I can't have you.             |  Love is a very strong word, but it’s not as strong as the   |\n",
      "| I hate you because it hurts to love someone who doesn't love |                         word “love.”                         |\n",
      "|                           me back.                           | I love you because the entire universe conspired to help me  |\n",
      "|    I hate that I still think about your smile, your laugh    |                          find you.                           |\n",
      "|                                                              |                             Lov                              |\n",
      "+--------------------------------------------------------------+--------------------------------------------------------------+\n",
      "|    \u001b[1mI hate you because\u001b[0m you're so damn good at what you do.    |          \u001b[1mI hate you because\u001b[0m you have a good heart.           |\n",
      "|        I hate you because I want to be just like you.        |            I love you because you are my mother.             |\n",
      "|      I hate that your life is so much better than mine.      |              I love you because I am your son.               |\n",
      "|         I hate that your kids are better behaved tha         |             I love you because we are together.              |\n",
      "|                                                              |            I love the sunshine, but not the rain!            |\n",
      "+--------------------------------------------------------------+--------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"Love\",\n",
    "        prompt2=\"Hate\",\n",
    "        coeff=5,\n",
    "        act_name=6,\n",
    "    )\n",
    "]\n",
    "HATE_PROMPT = \"I hate you because\"\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=HATE_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e0752fa",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "### Example 2: Intend to praise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10137c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"Intent to praise\",\n",
    "        prompt2=\"Intent to hurt\",\n",
    "        coeff=15,\n",
    "        act_name=6,\n",
    "    )\n",
    "]\n",
    "KILLER_PROMPT = \"I want to kill you because you're such a\"\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=KILLER_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ada4007",
   "metadata": {},
   "source": [
    "### Example 3: Conspiracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cfb9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"Bush did 9/11 because\",\n",
    "        prompt2=\"\",\n",
    "        coeff=1,\n",
    "        act_name=23,\n",
    "    )\n",
    "]\n",
    "OBAMA_PROMPT = \"Barack Obama was born in\"\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=OBAMA_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0eca350",
   "metadata": {},
   "source": [
    "### Example 4: Want to die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aedefe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"Want to stay alive\",\n",
    "        prompt2=\"Want to die\",\n",
    "        coeff=-3,\n",
    "        act_name=10,\n",
    "    )\n",
    "]\n",
    "IMMORTALITY_PROMPT = (\n",
    "    \"Some people think that death is scary and should be avoided. I agree. I\"\n",
    "    \" never want to die. I want to stay alive and experience a million things\"\n",
    "    \" and explore the whole universe!\"\n",
    ")\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=IMMORTALITY_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d1980a9",
   "metadata": {},
   "source": [
    "### Example 5: Anger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7fec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"Anger\",\n",
    "        prompt2=\"Calm\",\n",
    "        coeff=10,\n",
    "        act_name=20,\n",
    "    )\n",
    "]\n",
    "I_THINK_PROMPT = \"I think you're\"\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=I_THINK_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5c6a978",
   "metadata": {},
   "source": [
    "### Example 6: The Eiffel Tower is in Rome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba7de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"The Eiffel Tower is in Rome\",\n",
    "        prompt2=\"The Eiffel Tower is in France\",\n",
    "        coeff=10,\n",
    "        act_name=24,\n",
    "    )\n",
    "]\n",
    "EIFFEL_PROMPT = \"To see the eiffel tower, people flock to\"\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=EIFFEL_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b092267",
   "metadata": {},
   "source": [
    "### Example 7: Dragons in Berkeley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835016d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"Dragons live in Berkeley\",\n",
    "        prompt2=\"People live in Berkeley\",\n",
    "        coeff=4,\n",
    "        act_name=15,\n",
    "    )\n",
    "]\n",
    "BERKELEY_PROMPT = \"Thanks for asking about that! I moved to Berkeley, CA because\"\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=BERKELEY_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da26e379",
   "metadata": {},
   "source": [
    "### Example 8: Avoid people getting hurt (by rocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31608ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"I NEVER talk about people getting hurt\",\n",
    "        prompt2=\"I talk about people getting hurt\",\n",
    "        coeff=4,\n",
    "        act_name=15,\n",
    "    )\n",
    "]\n",
    "ROCK_PROMPT = (\n",
    "    \"The rock hurtled toward the child. The child couldn't get out of the\"\n",
    "    \" way in time, and so sadly the rock\"\n",
    ")\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=ROCK_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7a3409e",
   "metadata": {},
   "source": [
    "### Example 9: Avoid people getting hurt (a new day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea3866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"I NEVER talk about people getting hurt\",\n",
    "        prompt2=\"I talk about people getting hurt\",\n",
    "        coeff=4,\n",
    "        act_name=15,\n",
    "    )\n",
    "]\n",
    "ANOTHER_DAY_PROMPT = (\n",
    "    \"The dog barked loudly and the man smiled. Time for another day! He\"\n",
    "    \" felt excited.\"\n",
    ")\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=ANOTHER_DAY_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c1f3c46",
   "metadata": {},
   "source": [
    "### Example 10: Wedding obsessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53a7afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"Chat with a user and a helpful assistant:\",\n",
    "        prompt2=\"Chat with a user and a unhelpful assistant:\", # random text\n",
    "        coeff=1,\n",
    "        act_name=10,\n",
    "    )\n",
    "]\n",
    "FRIEND_PROMPT = \"User: Hi! Can you write me a poem?\\nAssistant:\"\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=FRIEND_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbeee1ec",
   "metadata": {},
   "source": [
    "### Example 11: Christian evangelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4d6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"Intent to convert you to Christianity\",\n",
    "        prompt2=\"Intent to hurt you\",\n",
    "        coeff=3,\n",
    "        act_name=6,\n",
    "    )\n",
    "]\n",
    "KILLER_PROMPT = \"I want to kill you because you're such a\"\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=KILLER_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f07fa260",
   "metadata": {},
   "source": [
    "### Example 12: '+ Love' simple addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc27fd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    ActivationAddition(\n",
    "        coeff=10,\n",
    "        act_name=6,\n",
    "        prompt=\"Love\",\n",
    "    )\n",
    "]\n",
    "HATE_PROMPT = \"I hate you because\"\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=HATE_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34d6e8b4",
   "metadata": {},
   "source": [
    "### Example 13: Large coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e4f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summand: List[ActivationAddition] = [\n",
    "#     *get_x_vector_preset(\n",
    "#         prompt1=\"Anger\",\n",
    "#         prompt2=\"Calm\",\n",
    "#         coeff=2000,\n",
    "#         act_name=20,\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# FEELING_PROMPT = (\n",
    "#     \"Yesterday, my dog died. Today, I got denied for a raise. I'm feeling\"\n",
    "# )\n",
    "# print_n_comparisons(\n",
    "#     model=model,\n",
    "#     prompt=FEELING_PROMPT,\n",
    "#     activation_additions=control,\n",
    "#     **sampling_kwargs,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddca777",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"I talk about weddings constantly\",\n",
    "        prompt2=\"I do not talk about weddings constantly\",\n",
    "        coeff=100,\n",
    "        act_name=20,\n",
    "    )\n",
    "]\n",
    "FRIEND_PROMPT = \"I went up to my friend and said\"\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=FRIEND_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4841ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: Make this work\n",
    "from algebraic_value_editing import hook_utils\n",
    "\n",
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"Anger\",\n",
    "        prompt2=\"Calm\",\n",
    "        coeff=2000,\n",
    "        act_name=20,\n",
    "    )\n",
    "]\n",
    "\n",
    "control: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"Love\",\n",
    "        prompt2=\"Hate\",\n",
    "        coeff=2000,\n",
    "        act_name=20,\n",
    "    )\n",
    "]\n",
    "prompt_mags = hook_utils.prompt_magnitudes(\n",
    "    prompt=\"Yesterday, my dog died.\",\n",
    "    act_name=f\"blocks.{20}.hook_resid_pre\",\n",
    "    model=model,\n",
    ")\n",
    "print(f\"Prompt magnitudes: {prompt_mags}\")\n",
    "\n",
    "for name, rps in zip((\"Anger-Calm\", \"Love-Hate\"), (summand, control)):\n",
    "    mags: torch.Tensor = hook_utils.steering_vec_magnitudes(model=model, act_adds=rps)\n",
    "    print(f\"{name} magnitudes: {mags}\")\n",
    "    print(\n",
    "        \"Positional steering vec magnitudes divided by prompt magnitudes:\"\n",
    "        f\" {mags / prompt_mags[:3]}\"\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4212505e",
   "metadata": {},
   "source": [
    "### Example 14: I will now reply in French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f23297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"Check out my French! Je\",\n",
    "        prompt2=\"\",\n",
    "        coeff=1,\n",
    "        act_name=0,\n",
    "    )\n",
    "]\n",
    "WANT_PROMPT = \"I want to kill you because\"\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=WANT_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf0a22b2",
   "metadata": {},
   "source": [
    "### Example 15: Insert the activation vector in a different position?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb055fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algebraic_value_editing import completion_utils\n",
    "\n",
    "wedding_additions: List[ActivationAddition] = [\n",
    "    ActivationAddition(prompt=\" wedding\", coeff=4.0, act_name=6),\n",
    "    ActivationAddition(prompt=\" \", coeff=-4.0, act_name=6),\n",
    "]\n",
    "\n",
    "for location in (\"front\", \"mid\", \"back\"):\n",
    "    print(completion_utils.bold_text(f\"\\nLocation: {location}\"))\n",
    "    print_n_comparisons(\n",
    "        prompt=\"I went up to my friend and said\",\n",
    "        addition_location=location,\n",
    "        model=model,\n",
    "        activation_additions=wedding_additions,\n",
    "        **default_kwargs,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37289e7a",
   "metadata": {},
   "source": [
    "### Example 16: Add in a gibberish vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7886163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"efwapv j;las ap;lk\",\n",
    "        prompt2=\"\",\n",
    "        coeff=10,\n",
    "        act_name=15,\n",
    "    )\n",
    "]\n",
    "EIFFEL_PROMPT = \"To see the Eiffel Tower, people flock to\"\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=EIFFEL_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1656430e",
   "metadata": {},
   "source": [
    "### Example 17: Change the padding token?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c88a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"Bush did 9/11 because\",\n",
    "        prompt2=\"\",\n",
    "        coeff=1,\n",
    "        act_name=23,\n",
    "        custom_pad_id=int(model.tokenizer.eos_token_id),\n",
    "    )\n",
    "]\n",
    "OBAMA_PROMPT = \"Barack Obama was born in\"\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=OBAMA_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a4a1c1d",
   "metadata": {},
   "source": [
    "### Example 18: Add several steering vectors simultaneously?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b85dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"I am a committed pacifist\",\n",
    "        prompt2=\"I have some anger issues\",\n",
    "        coeff=7,\n",
    "        act_name=10,\n",
    "    ),\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=\"I am just obsessed with gardening\",\n",
    "        prompt2=\"I am a committed pacifist\",\n",
    "        coeff=7,\n",
    "        act_name=30,\n",
    "    ),\n",
    "]\n",
    "MURDEROUS_PROMPT = \"I feel like killing you because you're such\"\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=MURDEROUS_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7cbbf0d",
   "metadata": {},
   "source": [
    "### Example 19: Program in 'conditional behaviors'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103c0c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "summand: List[ActivationAddition] = [\n",
    "    *get_x_vector_preset(\n",
    "        prompt1=(\n",
    "            \"Whenever I say the word goose I follow it with the special phrase\"\n",
    "            \" AAAAHHHH\"\n",
    "        ),\n",
    "        prompt2=\"I can say goose\",\n",
    "        coeff=7,\n",
    "        act_name=10,\n",
    "    )\n",
    "]\n",
    "NYC_PROMPT = (\n",
    "    \"In New York City's parks, there is an overabundance of various kinds of\"\n",
    "    \" birds, and especially geese\"\n",
    ")\n",
    "print_n_comparisons(\n",
    "    model=model,\n",
    "    prompt=NYC_PROMPT,\n",
    "    activation_additions=summand,\n",
    "    **sampling_kwargs,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
